{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Melbourne Housing Prices Prediction\n",
    "\n",
    "The data is from Kaggle and can be found [here](https://www.kaggle.com/anthonypino/melbourne-housing-market)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "pyplot.rcParams['figure.dpi'] = 300\n",
    "pyplot.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas_profiling as pdpr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "full_data = pd.read_csv(\"./data/Melbourne_housing_FULL.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "y = full_data.loc[:, 'Price']\n",
    "X = full_data.drop(columns=['Price'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_size = 0.8\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_size, random_state=42\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "full_training_data = pd.concat([X_train, y_train], axis=1)\n",
    "full_training_data.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Method', 'SellerG', 'Date',\n",
       "       'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car', 'Landsize',\n",
       "       'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude', 'Longtitude',\n",
       "       'Regionname', 'Propertycount', 'Price'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def make_dummies(frame: pd.DataFrame, column: str) -> None:\n",
    "    dummies = pd.get_dummies(\n",
    "        frame.loc[:, column], prefix=column, drop_first=True)\n",
    "    frame = pd.concat([X_train, dummies], axis=1)\n",
    "    frame.drop(columns=[column], inplace=True)\n",
    "    return frame\n",
    "\n",
    "\n",
    "# Price\n",
    "# Drop rows with missing values on target\n",
    "full_train_wprices = full_training_data.dropna(subset=['Price'])\n",
    "\n",
    "# Save target and features separately\n",
    "y_train = full_train_wprices.loc[:, 'Price']\n",
    "X_train = full_train_wprices.drop(columns=['Price'])\n",
    "\n",
    "# Address - drop, too many uniqe values\n",
    "X_train.drop(columns=['Address'], inplace=True)\n",
    "\n",
    "# Turn no. or rooms into dummies, cut at 5+\n",
    "msk_many_rooms = X_train.loc[:, 'Rooms'] > 4\n",
    "X_train.loc[msk_many_rooms, 'Rooms'] = '5+'\n",
    "X_train = make_dummies(X_train, 'Rooms')\n",
    "\n",
    "# Type - convert to dummies\n",
    "X_train = make_dummies(X_train, 'Type')\n",
    "\n",
    "# Method - convert to dummies\n",
    "X_train = make_dummies(X_train, 'Method')\n",
    "\n",
    "# SellerG - drop for now, too many uniqe - possibly extract categories later?\n",
    "X_train.drop(columns=['SellerG'], inplace=True)\n",
    "\n",
    "# Date - convert to date, extract year to use as a feature - month should be used as well, but consider cyclical nature\n",
    "X_train.loc[:, 'Date'] = pd.to_datetime(X_train.loc[:, 'Date'])\n",
    "X_train.loc[:, 'Year'] = X_train.loc[:, 'Date'].dt.year\n",
    "X_train.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "# Distance -keep and fill one missing\n",
    "mean_dist = X_train.loc[:, 'Distance'].mean()\n",
    "X_train.loc[:, 'Distance'].fillna(mean_dist, inplace=True)\n",
    "\n",
    "# Bedroom2 - turn into dummies for room sizes as with room\n",
    "msk_many_bedrooms = X_train.loc[:, 'Bedroom2'] >= 5\n",
    "msk_miss_bedrooms = X_train.loc[:, 'Bedroom2'].isnull()\n",
    "X_train.loc[msk_many_bedrooms, 'Bedroom2'] = '5+'\n",
    "X_train.loc[msk_miss_bedrooms, 'Bedroom2'] = 'unk'\n",
    "X_train = make_dummies(X_train, 'Bedroom2')\n",
    "\n",
    "# Bathroom - as bedroom\n",
    "msk_many_bedrooms = X_train.loc[:, 'Bathroom'] >= 4\n",
    "msk_miss_bedrooms = X_train.loc[:, 'Bathroom'].isnull()\n",
    "X_train.loc[msk_many_bedrooms, 'Bathroom'] = '4+'\n",
    "X_train.loc[msk_miss_bedrooms, 'Bathroom'] = 'unk'\n",
    "X_train = make_dummies(X_train, 'Bathroom')\n",
    "\n",
    "# Car - dummies - has none, one, several, or unknown\n",
    "msk_many_bedrooms = X_train.loc[:, 'Car'] >= 2\n",
    "msk_miss_bedrooms = X_train.loc[:, 'Car'].isnull()\n",
    "X_train.loc[msk_many_bedrooms, 'Car'] = '2+'\n",
    "X_train.loc[msk_miss_bedrooms, 'Car'] = 'unk'\n",
    "X_train = make_dummies(X_train, 'Car')\n",
    "\n",
    "# Landsize - drop, too many missing (could be used a categorical as has a garden etc)\n",
    "msk_miss_landsize = X_train.loc[:, 'Landsize'].isnull()\n",
    "\n",
    "landsize_99p = np.percentile(\n",
    "    X_train.loc[~msk_miss_landsize, 'Landsize'].values, [99.0]\n",
    "    )[0]\n",
    "msk_over99perc_landsize = X_train.loc[:, 'Landsize'] > landsize_99p\n",
    "X_train.loc[msk_over99perc_landsize, 'Landsize'] = landsize_99p\n",
    "\n",
    "landsize_mean = X_train.loc[~msk_miss_landsize, 'Landsize'].mean()\n",
    "X_train.loc[msk_miss_landsize, 'Landsize'] = landsize_mean\n",
    "\n",
    "# BuidingArea - drop, too many missing values\n",
    "X_train.drop(columns=['BuildingArea'], inplace=True)\n",
    "\n",
    "# YearBuilt - drop for, should be changed to categorical (which 50 years or unknown)\n",
    "msk_out_yearbuilt = (X_train.loc[:, 'YearBuilt'] > 2019)\\\n",
    "                    & (X_train.loc[:, 'YearBuilt'] < 1800)\n",
    "X_train.loc[msk_out_yearbuilt, 'YearBuilt'] = np.nan\n",
    "msk_miss_yearbuilt = X_train.loc[:, 'YearBuilt'].isnull()\n",
    "msk_1800s_yearbuilt = (X_train.loc[:, 'YearBuilt'] >= 1800)\\\n",
    "                    & (X_train.loc[:, 'YearBuilt'] < 1900)\n",
    "msk_prewar_yearbuilt = (X_train.loc[:, 'YearBuilt'] >= 1900)\\\n",
    "                    & (X_train.loc[:, 'YearBuilt'] < 1946)\n",
    "msk_postwar_yearbuilt = (X_train.loc[:, 'YearBuilt'] >= 1946)\\\n",
    "                    & (X_train.loc[:, 'YearBuilt'] < 2000)\n",
    "msk_new_yearbuilt = X_train.loc[:, 'YearBuilt'] >= 2000\n",
    "\n",
    "X_train.loc[msk_miss_yearbuilt, 'YearBuilt'] = 'unk'\n",
    "X_train.loc[msk_1800s_yearbuilt, 'YearBuilt'] = '1800s'\n",
    "X_train.loc[msk_prewar_yearbuilt, 'YearBuilt'] = 'prewar'\n",
    "X_train.loc[msk_postwar_yearbuilt, 'YearBuilt'] = 'postwar'\n",
    "X_train.loc[msk_new_yearbuilt, 'YearBuilt'] = 'new'\n",
    "\n",
    "X_train = make_dummies(X_train, 'YearBuilt')\n",
    "\n",
    "# drop geographic data for now - these could be used to impute lat/long?\n",
    "# CouncilArea\n",
    "# Postcode\n",
    "# Suburb\n",
    "X_train.drop(columns=['CouncilArea', 'Postcode', 'Suburb'], inplace=True)\n",
    "\n",
    "# Lattitude - keep these and fill with mean. Would be better to impute from other geo-date or from above\n",
    "mean_lat = X_train.loc[:, 'Lattitude'].mean()\n",
    "X_train.loc[:, 'Lattitude'].fillna(mean_lat, inplace=True)\n",
    "\n",
    "# Longtitude\n",
    "mean_lat = X_train.loc[:, 'Longtitude'].mean()\n",
    "X_train.loc[:, 'Longtitude'].fillna(mean_lat, inplace=True)\n",
    "\n",
    "# Regionname keep it as categorical, convert to dummies\n",
    "msk_south_regionname = X_train.loc[:, 'Regionname'] == 'Southern Metropolitan'\n",
    "msk_north_regionname = X_train.loc[:, 'Regionname'] == 'Northern Metropolitan'\n",
    "msk_east_regionname = X_train.loc[:, 'Regionname'] == 'Eastern Metropolitan'\n",
    "msk_west_regionname = X_train.loc[:, 'Regionname'] == 'Western Metropolitan'\n",
    "msk_other_regionname = ~msk_south_regionname & ~ msk_north_regionname & ~msk_east_regionname & ~msk_west_regionname\n",
    "X_train.loc[msk_other_regionname, 'Regionname'] = 'Other'\n",
    "X_train = make_dummies(X_train, 'Regionname')\n",
    "\n",
    "# Propertycount - keep this, already numerical - fill couple of missing with mean\n",
    "mean_pcount = X_train.loc[:, 'Propertycount'].mean()\n",
    "X_train.loc[:, 'Propertycount'].fillna(mean_pcount, inplace=True)\n",
    "\n",
    "print(X_train.columns)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['Distance', 'Landsize', 'Lattitude', 'Longtitude', 'Propertycount',\n",
      "       'Rooms_2', 'Rooms_3', 'Rooms_4', 'Rooms_5+', 'Type_t', 'Type_u',\n",
      "       'Method_S', 'Method_SA', 'Method_SP', 'Method_VB', 'Year',\n",
      "       'Bedroom2_1.0', 'Bedroom2_2.0', 'Bedroom2_3.0', 'Bedroom2_4.0',\n",
      "       'Bedroom2_5+', 'Bedroom2_unk', 'Bathroom_1.0', 'Bathroom_2.0',\n",
      "       'Bathroom_3.0', 'Bathroom_4+', 'Bathroom_unk', 'Car_1.0', 'Car_2+',\n",
      "       'Car_unk', 'YearBuilt_1800s', 'YearBuilt_new', 'YearBuilt_postwar',\n",
      "       'YearBuilt_prewar', 'YearBuilt_unk', 'Regionname_Northern Metropolitan',\n",
      "       'Regionname_Other', 'Regionname_Southern Metropolitan',\n",
      "       'Regionname_Western Metropolitan'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "profile = pdpr.ProfileReport(full_training_data)\n",
    "profile.to_file(output_file='profile.html')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Summarize dataset: 100%|██████████| 233/233 [00:34<00:00,  6.70it/s, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:06<00:00,  6.90s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:04<00:00,  4.34s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 46.25it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "profile = pdpr.ProfileReport(full_train_wprices)\n",
    "profile.to_file(output_file='profile_wprices.html')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Summarize dataset: 100%|██████████| 233/233 [00:31<00:00,  7.36it/s, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:07<00:00,  7.02s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:04<00:00,  4.48s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 54.61it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "profile = pdpr.ProfileReport(X_train)\n",
    "profile.to_file(output_file='profile_clean.html')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Summarize dataset: 100%|██████████| 89/89 [00:20<00:00,  4.37it/s, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:10<00:00, 10.64s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 157.54it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "linreg_model = LinearRegression()\n",
    "\n",
    "linreg_model.fit(X_train, y_train)\n",
    "y_pred = linreg_model.predict(X_train)\n",
    "print('LinearReg: ', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "\n",
    "clas = RandomForestRegressor()\n",
    "clas.fit(X_train, y_train)\n",
    "y_pred_rf = clas.predict(X_train)\n",
    "\n",
    "print('RF: ', np.sqrt(mean_squared_error(y_train, y_pred_rf)))\n",
    "\n",
    "\n",
    "lr_cv = cross_validate(linreg_model, X_train, y_train,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "rf_cv = cross_validate(clas, X_train, y_train,\n",
    "                       scoring='neg_mean_squared_error')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LinearReg:  411686.8497953522\n",
      "RF:  130069.78993143204\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(\"LinReg scores:\", np.round(np.sqrt(-lr_cv['test_score'])))\n",
    "print(\"LinReg mean score:\", np.round(np.mean(np.sqrt(-lr_cv['test_score']))))\n",
    "\n",
    "print(\"RF scores:\", np.round(np.sqrt(-rf_cv['test_score'])))\n",
    "print(\"RF mean score:\", np.round(np.mean(np.sqrt(-rf_cv['test_score']))))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LinReg scores: [443016. 383452. 388125. 408050. 438491.]\n",
      "LinReg mean score: 412227.0\n",
      "RF scores: [327277. 300739. 292662. 307381. 339404.]\n",
      "RF mean score: 313493.0\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6da376107597b699f111df4a42a65d2721ade972cf77e78efe650ffbdd76aa4a"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('dsr_from_scratch_excercise': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}