{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melbourne Housing Prices Prediction\n",
    "\n",
    "The data is from Kaggle and can be found [here](https://www.kaggle.com/anthonypino/melbourne-housing-market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "pyplot.rcParams['figure.dpi'] = 300\n",
    "pyplot.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas_profiling as pdpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(\"./data/Melbourne_housing_FULL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = full_data.loc[:, 'Price']\n",
    "X = full_data.drop(columns=['Price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_size, random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_data = pd.concat([X_train, y_train], axis=1)\n",
    "full_training_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dummies(frame: pd.DataFrame, column: str) -> None:\n",
    "    dummies = pd.get_dummies(\n",
    "        frame.loc[:, column], prefix=column, drop_first=True)\n",
    "    frame = pd.concat([X_train, dummies], axis=1)\n",
    "    frame.drop(columns=[column], inplace=True)\n",
    "    return frame\n",
    "\n",
    "\n",
    "# Price\n",
    "# Drop rows with missing values on target\n",
    "full_train_wprices = full_training_data.dropna(subset=['Price'])\n",
    "\n",
    "# Save target and features separately\n",
    "y_train = full_train_wprices.loc[:, 'Price']\n",
    "X_train = full_train_wprices.drop(columns=['Price'])\n",
    "\n",
    "# Address - drop, too many uniqe values\n",
    "X_train.drop(columns=['Address'], inplace=True)\n",
    "\n",
    "# Turn no. or rooms into dummies, cut at 5+\n",
    "#msk_many_rooms = X_train.loc[:, 'Rooms'] > 4\n",
    "#X_train.loc[msk_many_rooms, 'Rooms'] = '5+'\n",
    "#X_train = make_dummies(X_train, 'Rooms')\n",
    "\n",
    "# Type - convert to dummies\n",
    "X_train = make_dummies(X_train, 'Type')\n",
    "\n",
    "# Method - convert to dummies\n",
    "X_train = make_dummies(X_train, 'Method')\n",
    "\n",
    "# SellerG - drop for now, too many uniqe - possibly extract categories later?\n",
    "X_train.drop(columns=['SellerG'], inplace=True)\n",
    "\n",
    "# Date - convert to date, extract year to use as a feature - month should be used as well, but consider cyclical nature\n",
    "X_train.loc[:, 'Date'] = pd.to_datetime(X_train.loc[:, 'Date'])\n",
    "X_train.loc[:, 'Year'] = X_train.loc[:, 'Date'].dt.year\n",
    "X_train.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "# Distance -keep and fill one missing\n",
    "mean_dist = X_train.loc[:, 'Distance'].mean()\n",
    "X_train.loc[:, 'Distance'].fillna(mean_dist, inplace=True)\n",
    "\n",
    "# Bedroom2 - turn into dummies for room sizes as with room\n",
    "#msk_many_bedrooms = X_train.loc[:, 'Bedroom2'] >= 5\n",
    "msk_miss_bedrooms = X_train.loc[:, 'Bedroom2'].isnull()\n",
    "#print(msk_miss_bedrooms)\n",
    "#X_train.loc[msk_many_bedrooms, 'Bedroom2'] = '5+'\n",
    "#X_train.loc[msk_miss_bedrooms, 'Bedroom2'] = 'unk'\n",
    "mode_bedroom2 = X_train.loc[~msk_miss_bedrooms, 'Bedroom2'].mode()\n",
    "#print(type(mode_bedroom2[0]))\n",
    "X_train.loc[msk_miss_bedrooms, 'Bedroom2'] = mode_bedroom2[0]\n",
    "\n",
    "X_train.loc[:, 'Bedroom2'] = X_train.loc[:, 'Bedroom2'] / X_train.loc[:, 'Rooms']\n",
    "\n",
    "\n",
    "#print(X_train.loc[msk_miss_bedrooms, 'Bedroom2'])\n",
    "\n",
    "#X_train = make_dummies(X_train, 'Bedroom2')\n",
    "\n",
    "# Bathroom - as bedroom\n",
    "#msk_many_bedrooms = X_train.loc[:, 'Bathroom'] >= 4\n",
    "msk_miss_bedrooms = X_train.loc[:, 'Bathroom'].isnull()\n",
    "#X_train.loc[msk_many_bedrooms, 'Bathroom'] = '4+'\n",
    "#X_train.loc[msk_miss_bedrooms, 'Bathroom'] = 'unk'\n",
    "mode_bathroom = X_train.loc[:, 'Bathroom'].mode()[0]\n",
    "X_train.loc[msk_miss_bedrooms, 'Bathroom'] = mode_bathroom\n",
    "X_train.loc[msk_miss_bedrooms, 'Bathroom'] = X_train.loc[msk_miss_bedrooms, 'Bathroom'] / X_train.loc[:, 'Rooms']\n",
    "\n",
    "\n",
    "#X_train = make_dummies(X_train, 'Bathroom')\n",
    "\n",
    "# Car - dummies - has none, one, several, or unknown\n",
    "msk_many_bedrooms = X_train.loc[:, 'Car'] >= 2\n",
    "msk_miss_bedrooms = X_train.loc[:, 'Car'].isnull()\n",
    "X_train.loc[msk_many_bedrooms, 'Car'] = '2+'\n",
    "X_train.loc[msk_miss_bedrooms, 'Car'] = 'unk'\n",
    "X_train = make_dummies(X_train, 'Car')\n",
    "\n",
    "# Landsize - drop, too many missing (could be used a categorical as has a garden etc)\n",
    "msk_miss_landsize = X_train.loc[:, 'Landsize'].isnull()\n",
    "\n",
    "landsize_99p = np.percentile(\n",
    "    X_train.loc[~msk_miss_landsize, 'Landsize'].values, [99.0]\n",
    "    )[0]\n",
    "msk_over99perc_landsize = X_train.loc[:, 'Landsize'] > landsize_99p\n",
    "X_train.loc[msk_over99perc_landsize, 'Landsize'] = landsize_99p\n",
    "\n",
    "landsize_mean = X_train.loc[~msk_miss_landsize, 'Landsize'].mean()\n",
    "X_train.loc[msk_miss_landsize, 'Landsize'] = landsize_mean\n",
    "\n",
    "# BuidingArea - drop, too many missing values\n",
    "X_train.drop(columns=['BuildingArea'], inplace=True)\n",
    "\n",
    "# YearBuilt - drop for, should be changed to categorical (which 50 years or unknown)\n",
    "msk_out_yearbuilt = (X_train.loc[:, 'YearBuilt'] > 2019)\\\n",
    "                    & (X_train.loc[:, 'YearBuilt'] < 1800)\n",
    "X_train.loc[msk_out_yearbuilt, 'YearBuilt'] = np.nan\n",
    "msk_miss_yearbuilt = X_train.loc[:, 'YearBuilt'].isnull()\n",
    "msk_1800s_yearbuilt = (X_train.loc[:, 'YearBuilt'] >= 1800)\\\n",
    "                    & (X_train.loc[:, 'YearBuilt'] < 1900)\n",
    "msk_prewar_yearbuilt = (X_train.loc[:, 'YearBuilt'] >= 1900)\\\n",
    "                    & (X_train.loc[:, 'YearBuilt'] < 1946)\n",
    "msk_postwar_yearbuilt = (X_train.loc[:, 'YearBuilt'] >= 1946)\\\n",
    "                    & (X_train.loc[:, 'YearBuilt'] < 2000)\n",
    "msk_new_yearbuilt = X_train.loc[:, 'YearBuilt'] >= 2000\n",
    "\n",
    "X_train.loc[msk_miss_yearbuilt, 'YearBuilt'] = 'unk'\n",
    "X_train.loc[msk_1800s_yearbuilt, 'YearBuilt'] = '1800s'\n",
    "X_train.loc[msk_prewar_yearbuilt, 'YearBuilt'] = 'prewar'\n",
    "X_train.loc[msk_postwar_yearbuilt, 'YearBuilt'] = 'postwar'\n",
    "X_train.loc[msk_new_yearbuilt, 'YearBuilt'] = 'new'\n",
    "\n",
    "X_train = make_dummies(X_train, 'YearBuilt')\n",
    "\n",
    "# Lattitude - keep these and fill with mean. Would be better to impute from other geo-date or from above\n",
    "\n",
    "msk_empty_lats = X_train.loc[:, 'Lattitude'].isnull()\n",
    "msk_empty_longs = X_train.loc[:, 'Lattitude'].isnull()\n",
    "\n",
    "msk_empty_locs = msk_empty_lats | msk_empty_longs\n",
    "\n",
    "mean_lats_1 = X_train.loc[~msk_empty_locs, ['Suburb', 'Lattitude', 'Longtitude']].groupby(['Suburb']).mean()\n",
    "mean_lats_2 = X_train.loc[~msk_empty_locs, ['CouncilArea', 'Suburb', 'Lattitude', 'Longtitude']].groupby(['CouncilArea', 'Suburb']).mean()\n",
    "mean_lats_3 = X_train.loc[~msk_empty_locs, ['CouncilArea', 'Postcode', 'Suburb', 'Lattitude', 'Longtitude']].groupby(['CouncilArea', 'Postcode', 'Suburb']).mean()\n",
    "mean_lats_4 = X_train.loc[~msk_empty_locs, ['CouncilArea', 'Postcode', 'Lattitude', 'Longtitude']].groupby(['CouncilArea', 'Postcode']).mean()\n",
    "mean_lats_5 = X_train.loc[~msk_empty_locs, ['CouncilArea', 'Lattitude', 'Longtitude']].groupby(['CouncilArea']).mean()\n",
    "mean_lats_6 = X_train.loc[~msk_empty_locs, ['Postcode', 'Lattitude', 'Longtitude']].groupby(['Postcode']).mean()\n",
    "\n",
    "#print(mean_lats)\n",
    "#print(mean_lats.loc['Yarra Ranges Shire Council'].loc[3116.0].loc['Chirnside Park', 'Lattitude']) #['Yarra Ranges Shire Council'])#[3775.0]['Yarra Glen'])#         -37.653910\n",
    "mean_lat = X_train.loc[:, 'Lattitude'].mean()\n",
    "mean_long = X_train.loc[:, 'Longtitude'].mean()\n",
    "\n",
    "for index, item in X_train.loc[msk_empty_locs, :].iterrows():\n",
    "    #print(mean_lats.loc[item['CouncilArea']].loc[item['Postcode']].loc[item['Suburb'], \"Lattitude\"])\n",
    "    try:\n",
    "        X_train.loc[index, 'Lattitude'] = mean_lats_3.loc[item['CouncilArea']].loc[item['Postcode']].loc[item['Suburb'], \"Lattitude\"]\n",
    "        X_train.loc[index, 'Longtitude'] = mean_lats_3.loc[item['CouncilArea']].loc[item['Postcode']].loc[item['Suburb'], 'Longtitude']\n",
    "\n",
    "    except KeyError:\n",
    "        try:\n",
    "            X_train.loc[index, 'Lattitude'] = mean_lats_2.loc[item['CouncilArea']].loc[item['Suburb'], \"Lattitude\"]\n",
    "            X_train.loc[index, 'Longtitude'] = mean_lats_2.loc[item['CouncilArea']].loc[item['Suburb'], \"Longtitude\"]\n",
    "            \n",
    "        except KeyError:\n",
    "            try:\n",
    "                X_train.loc[index, 'Lattitude'] = mean_lats_1.loc[item['Suburb'], \"Lattitude\"]\n",
    "                X_train.loc[index, 'Longtitude'] = mean_lats_1.loc[item['Suburb'], \"Longtitude\"]\n",
    "\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    X_train.loc[index, 'Lattitude'] = mean_lats_4.loc[item['CouncilArea']].loc[item['Postcode'], \"Lattitude\"]\n",
    "                    X_train.loc[index, 'Longtitude'] = mean_lats_4.loc[item['CouncilArea']].loc[item['Postcode'], \"Longtitude\"]\n",
    "\n",
    "                except:\n",
    "                    try:\n",
    "                        X_train.loc[index, 'Lattitude'] = mean_lats_5.loc[item['CouncilArea'], \"Lattitude\"]\n",
    "                        X_train.loc[index, 'Longtitude'] = mean_lats_5.loc[item['CouncilArea'], \"Longtitude\"]\n",
    "                    except:\n",
    "                        try:\n",
    "                            X_train.loc[index, 'Lattitude'] = mean_lats_6.loc[item['Postcode'], \"Lattitude\"]\n",
    "                            X_train.loc[index, 'Longtitude'] = mean_lats_6.loc[item['Postcode'], \"Longtitude\"]\n",
    "                        except:\n",
    "                            X_train.loc[index, 'Lattitude'] = mean_lat\n",
    "                            X_train.loc[index, 'Longtitude'] = mean_long\n",
    "\n",
    "                            #print(item)\n",
    "\n",
    "X_train.loc[:, 'LatLong'] = (X_train.loc[:, 'Lattitude'] - mean_lat) * (X_train.loc[:, \"Longtitude\"] - mean_long)\n",
    "\n",
    "#mean_lat = X_train.loc[:, 'Lattitude'].mean()\n",
    "#X_train.loc[:, 'Lattitude'].fillna(mean_lat, inplace=True)\n",
    "\n",
    "# Longtitude\n",
    "#mean_long = X_train.loc[:, 'Longtitude'].mean()\n",
    "#X_train.loc[:, 'Longtitude'].fillna(mean_long, inplace=True)\n",
    "\n",
    "# drop geographic data for now - these could be used to impute lat/long?\n",
    "# CouncilArea\n",
    "# Postcode\n",
    "# Suburb\n",
    "X_train.drop(columns=['CouncilArea', 'Postcode', 'Suburb'], inplace=True)\n",
    "\n",
    "# Regionname keep it as categorical, convert to dummies\n",
    "msk_south_regionname = X_train.loc[:, 'Regionname'] == 'Southern Metropolitan'\n",
    "msk_north_regionname = X_train.loc[:, 'Regionname'] == 'Northern Metropolitan'\n",
    "msk_east_regionname = X_train.loc[:, 'Regionname'] == 'Eastern Metropolitan'\n",
    "msk_west_regionname = X_train.loc[:, 'Regionname'] == 'Western Metropolitan'\n",
    "msk_other_regionname = ~msk_south_regionname & ~ msk_north_regionname & ~msk_east_regionname & ~msk_west_regionname\n",
    "X_train.loc[msk_other_regionname, 'Regionname'] = 'Other'\n",
    "X_train = make_dummies(X_train, 'Regionname')\n",
    "\n",
    "# Propertycount - keep this, already numerical - fill couple of missing with mean\n",
    "mean_pcount = X_train.loc[:, 'Propertycount'].mean()\n",
    "X_train.loc[:, 'Propertycount'].fillna(mean_pcount, inplace=True)\n",
    "\n",
    "print(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pdpr.ProfileReport(full_training_data)\n",
    "profile.to_file(output_file='profile.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pdpr.ProfileReport(full_train_wprices)\n",
    "profile.to_file(output_file='profile_wprices.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pdpr.ProfileReport(X_train)\n",
    "profile.to_file(output_file='profile_clean.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_1 = Pipeline([('model', LinearRegression())])\n",
    "pipe_2 = Pipeline([('scaler', StandardScaler()), ('model', RandomForestRegressor())])\n",
    "\n",
    "# linreg_model = LinearRegression()\n",
    "\n",
    "# linreg_model.fit(X_train, y_train)\n",
    "# y_pred = linreg_model.predict(X_train)\n",
    "# print('LinearReg: ', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "\n",
    "# clas = RandomForestRegressor()\n",
    "# clas.fit(X_train, y_train)\n",
    "# y_pred_rf = clas.predict(X_train)\n",
    "\n",
    "# print('RF: ', np.sqrt(mean_squared_error(y_train, y_pred_rf)))\n",
    "\n",
    "\n",
    "# lr_cv = cross_validate(linreg_model, X_train, y_train,\n",
    "#                        scoring='neg_mean_squared_error')\n",
    "# rf_cv = cross_validate(clas, X_train, y_train,\n",
    "#                        scoring='neg_mean_squared_error')\n",
    "\n",
    "lr_cv = cross_validate(pipe_1, X_train, y_train,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "rf_cv = cross_validate(pipe_2, X_train, y_train,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LinReg scores:\", np.round(np.sqrt(-lr_cv['test_score'])))\n",
    "print(\"LinReg mean score:\", np.round(np.mean(np.sqrt(-lr_cv['test_score']))))\n",
    "\n",
    "print(\"RF scores:\", np.round(np.sqrt(-rf_cv['test_score'])))\n",
    "print(\"RF mean score:\", np.round(np.mean(np.sqrtq(-rf_cv['test_score']))))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ac8971da6bcbe4a1b80bd464d2d1540223112fa77eed9c024ebc2e75dde27d6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('melbourne-housing': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
